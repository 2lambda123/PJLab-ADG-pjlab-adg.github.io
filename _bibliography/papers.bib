---
---

@article{zhang2023uni3d,
  abbr={CVPR},
  title={Uni3D: A Unified Baseline for Multi-dataset 3D Object Detection},
  author={Zhang, Bo and Yuan, Jiakang and Shi, Botian and Chen, Tao and Li, Yikang and Qiao, Yu},
  journal={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2023},
  doi={},
  url={https://arxiv.org/abs/2303.06880},
  html={https://arxiv.org/abs/2303.06880},
  pdf={zhang2023uni3d.pdf},
  selected={true}
}

@article{yuan2023bi3d,
  abbr={CVPR},
  title={Bi3D: Bi-domain Active Learning for Cross-domain 3D Object Detection},
  author={Yuan, Jiakang and Zhang, Bo and Yan, Xiangchao and Chen, Tao and Shi, Botian and Li, Yikang and Qiao, Yu},
  journal={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2023},
  doi={},
  url={https://arxiv.org/abs/2303.05886},
  html={https://arxiv.org/abs/2303.05886},
  pdf={yuan2023bi3d.pdf},
  selected={true}
}

@article{li2023logonet,
  abbr={CVPR},
  title={LoGoNet: Towards Accurate 3D Object Detection with Local-to-Global Cross-Modal Fusion},
  author={Li, Xin and Ma, Tao and Hou, Yuenan and Shi, Botian and Yang, Yucheng and Liu, Youquan and Wu, Xingjiao and Chen, Qin and Li, Yikang and Qiao, Yu and others},
  journal={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2023},
  doi={},
  url={https://arxiv.org/abs/2303.03595},
  html={https://arxiv.org/abs/2303.03595},
  pdf={li2023logonet.pdf},
  selected={true}
}

@article{li2023lwsis,
  abbr={AAAI},
  title={LWSIS: LiDAR-guided Weakly Supervised Instance Segmentation for Autonomous Driving},
  author={Li, Xiang and Yin, Junbo and Shi, Botian and Li, Yikang and Yang, Ruigang and Shen, Jianbin},
  journal={Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)},
  year={2023},
  doi={},
  url={https://arxiv.org/abs/2212.03504},
  html={https://arxiv.org/abs/2212.03504},
  pdf={li2023lwsis.pdf},
  selected={true}
}

@article{yan2023joint,
  abbr={ICRA},
  title={Joint camera intrinsic and lidar-camera extrinsic calibration},
  author={Yan, Guohang and He, Feiyu and Shi, Chunlei and Cai, Xinyu and Li, Yikang},
  journal={International Conference on Robotics and Automation (ICRA)},
  year={2023},
  doi={},
  url={https://arxiv.org/abs/2202.13708},
  html={https://arxiv.org/abs/2202.13708},
  pdf={yan2023joint.pdf},
  selected={true}
}

@article{cai2023analyzing,
  abbr={ICRA},
  title={Analyzing Infrastructure LiDAR Placement with Realistic LiDAR},
  author={Cai, Xinyu and Jiang, Wentao and Xu, Runsheng and Zhao, Wenquan and Ma, Jiaqi and Liu, Si and Li, Yikang},
  journal={International Conference on Robotics and Automation (ICRA)},
  year={2023},
  doi={},
  url={https://arxiv.org/abs/2211.15975},
  html={https://arxiv.org/abs/2211.15975},
  pdf={cai2023analyzing.pdf},
  selected={true}
}

@article{wen2023bringing,
  abbr={AAMAS},
  title={Bringing Diversity to Autonomous Vehicles: An Interpretable Multi-vehicle Decision-making and Planning Framework},
  author={Wen, Licheng and Cai, Pinlong and Fu, Daocheng and Mao, Song and Li, Yikang},
  journal={Proceedings of the 22th International Conference on Autonomous Agents and MultiAgent Systems (AAMAS)},
  year={2023},
  doi={},
  url={https://arxiv.org/abs/2302.06803},
  html={https://arxiv.org/abs/2302.06803},
  pdf={wen2023bringing.pdf},
  selected={true}
}

@article{xia2023scpnet,
  abbr={CVPR},
  title={SCPNet: Semantic Scene Completion on Point Cloud},
  author={Xia, Zhaoyang and Liu, Youquan and Li, Xin and Zhu, Xinge and Ma, Yuexin and Li, Yikang and Hou, Yuenan and Qiao, Yu},
  journal={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2023},
  doi={},
  url={https://arxiv.org/abs/2303.06884},
  html={https://arxiv.org/abs/2303.06884},
  pdf={xia2023scpnet.pdf},
  selected={false}
}

@article{chen2023clip2scene,
  abbr={CVPR},
  title={CLIP2Scene: Towards Label-efficient 3D Scene Understanding by CLIP},
  author={Chen, Runnan and Liu, Youquan and Kong, Lingdong and Zhu, Xinge and Ma, Yuexin and Li, Yikang and Hou, Yuenan and Qiao, Yu and Wang, Wenping},
  journal={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2023},
  doi={},
  url={https://arxiv.org/abs/2301.04926},
  html={https://arxiv.org/abs/2301.04926},
  pdf={chen2023clip2scene.pdf},
  selected={false}
}

@article{ye2023closer,
  abbr={IJCV},
  title={A Closer Look at Few-Shot 3D Point Cloud Classification},
  author={Ye, Chuangguan and Zhu, Hongyuan and Zhang, Bo and Chen, Tao},
  journal={International Journal of Computer Vision},
  volume={131},
  number={3},
  pages={772--795},
  year={2023},
  publisher={Springer},
  doi={https://doi.org/10.1007/s11263-022-01731-4},
  url={https://link.springer.com/article/10.1007/s11263-022-01731-4},
  html={https://link.springer.com/article/10.1007/s11263-022-01731-4},
  pdf={ye2023closer.pdf},
  selected={false}
}

@article{fei2023generative,
  abbr={CVPR},
  title={Generative Diffusion Prior for Unified Image Restoration and Enhancement},
  author={Fei, Ben and Lyu, Zhaoyang and Pan, Liang and Zhang, Junzhe and Yang, Weidong and Luo, Tianyue and Zhang, Bo and Dai, Bo},
  journal={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2023},
  doi={},
  url={},
  selected={false}
}

@article{gao2023dynamic,
  abbr={RA-L},
  title={Dynamic Scenario Representation Learning for Motion Forecasting with Heterogeneous Graph Convolutional Recurrent Networks},
  author={Gao, Xing and Jia, Xiaogang and Li, Yikang and Xiong, Hongkai},
  journal={IEEE Robotics and Automation Letters (RA-L)},
  year={2023},
  doi={},
  url={https://arxiv.org/abs/2303.04364},
  html={https://arxiv.org/abs/2303.04364},
  pdf={gao2023dynamic.pdf},
  selected={false}
}

% 2022

@inproceedings{li2022homogeneous,
  abbr={ECCV},
  title={Homogeneous Multi-modal Feature Fusion and Interaction for 3D Object Detection},
  author={Li, Xin and Shi, Botian and Hou, Yuenan and Wu, Xingjiao and Ma, Tianlong and Li, Yikang and He, Liang},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXXVIII},
  pages={691--707},
  year={2022},
  organization={Springer},
  doi={https://doi.org/10.1007/978-3-031-19839-7_40},
  url={https://link.springer.com/chapter/10.1007/978-3-031-19839-7_40},
  html={https://arxiv.org/abs/2210.09615},
  pdf={li2022homogeneous.pdf},
  selected={true}
}

@inproceedings{chen2022tracing,
  abbr={ECCV},
  title={L-Tracing: Fast Light Visibility Estimation on Neural Surfaces by Sphere Tracing},
  author={Chen, Ziyu and Ding, Chenjing and Guo, Jianfei and Wang, Dongliang and Li, Yikang and Xiao, Xuan and Wu, Wei and Song, Li},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XV},
  pages={217--233},
  year={2022},
  organization={Springer},
  doi={https://doi.org/10.1007/978-3-031-19784-0_13},
  url={https://link.springer.com/chapter/10.1007/978-3-031-19784-0_13},
  html={https://link.springer.com/chapter/10.1007/978-3-031-19784-0_13},
  pdf={chen2022tracing.pdf},
  selected={true}
}

@inproceedings{cai2022general,
  abbr={ITSC},
  title={General Driving Behavior Model based on the Desired Safety Margin for Vehicle Flow Simulation},
  author={Cai, Pinlong and Zhang, Junjie and Zhao, Xuan and Li, Yikang},
  booktitle={IEEE 25th International Conference on Intelligent Transportation Systems (ITSC)},
  pages={743--748},
  year={2022},
  organization={IEEE},
  doi={https://doi.org/10.1109/ITSC55140.2022.9922057},
  url={https://ieeexplore.ieee.org/abstract/document/9922057},
  html={https://ieeexplore.ieee.org/abstract/document/9922057},
  pdf={cai2022general.pdf},
  selected={true}
}

@inproceedings{wei2022croon,
  abbr={IROS},
  title={Croon: Automatic multi-lidar calibration and refinement method in road scene},
  author={Wei, Pengjin and Yan, Guohang and Li, Yikang and Fang, Kun and Cai, Xinyu and Yang, Jie and Liu, Wei},
  booktitle={IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={12857--12863},
  year={2022},
  organization={IEEE},
  doi={https://doi.org/10.1109/IROS47612.2022.9981558},
  url={https://ieeexplore.ieee.org/abstract/document/9981558},
  html={https://arxiv.org/abs/2203.03182},
  pdf={wei2022croon.pdf},
  selected={true}
}

@inproceedings{hou2022point,
  abbr={CVPR},
  title={Point-to-voxel knowledge distillation for lidar semantic segmentation},
  author={Hou, Yuenan and Zhu, Xinge and Ma, Yuexin and Loy, Chen Change and Li, Yikang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8479--8488},
  year={2022},
  doi={https://doi.org/10.1109/CVPR52688.2022.00829},
  url={https://openaccess.thecvf.com/content/CVPR2022/html/Hou_Point-to-Voxel_Knowledge_Distillation_for_LiDAR_Semantic_Segmentation_CVPR_2022_paper.html},
  html={https://arxiv.org/abs/2206.02099},
  pdf={hou2022point.pdf},
  selected={true}
}

@inproceedings{bai2022speech,
  abbr={Multimedia},
  title={Speech Fusion to Face: Bridging the Gap Between Human's Vocal Characteristics and Facial Imaging},
  author={Bai, Yeqi and Ma, Tao and Wang, Lipo and Zhang, Zhenjie},
  booktitle={Proceedings of the 30th ACM International Conference on Multimedia},
  pages={2042--2050},
  year={2022},
  doi={https://doi.org/10.1145/3503161.3547850},
  url={https://dl.acm.org/doi/abs/10.1145/3503161.3547850},
  html={https://arxiv.org/abs/2006.05888},
  pdf={bai2022speech.pdf},
  selected={false}
}

@inproceedings{zhang2022learning,
  abbr={Multimedia},
  title={Learning cross-image object semantic relation in transformer for few-shot fine-grained image classification},
  author={Zhang, Bo and Yuan, Jiakang and Li, Baopu and Chen, Tao and Fan, Jiayuan and Shi, Botian},
  abstract={Few-shot fine-grained learning aims to classify a query image into one of a set of support categories with fine-grained differences. Although learning different objects' local differences via Deep Neural Networks has achieved success, how to exploit the query-support cross-image object semantic relations in Transformer-based architecture remains under-explored in the few-shot fine-grained scenario. In this work, we propose a Transformer-based double-helix model, namely HelixFormer, to achieve the cross-image object semantic relation mining in a bidirectional and symmetrical manner. The HelixFormer consists of two steps: 1) Relation Mining Process (RMP) across different branches, and 2) Representation Enhancement Process (REP) within each individual branch. By the designed RMP, each branch can extract fine-grained object-level Cross-image Semantic Relation Maps (CSRMs) using information from the other branch, ensuring better cross-image interaction in semantically related local object regions. Further, with the aid of CSRMs, the developed REP can strengthen the extracted features for those discovered semantically-related local regions in each branch, boosting the model's ability to distinguish subtle feature differences of fine-grained objects. Extensive experiments conducted on five public fine-grained benchmarks demonstrate that HelixFormer can effectively enhance the cross-image object semantic relation matching for recognizing fine-grained objects, achieving much better performance over most state-of-the-art methods under 1-shot and 5-shot scenarios.},
  booktitle={Proceedings of the 30th ACM International Conference on Multimedia},
  pages={2135--2144},
  year={2022},
  doi={https://doi.org/10.1145/3503161.3547961},
  url={https://dl.acm.org/doi/abs/10.1145/3503161.3547961},
  html={https://arxiv.org/abs/2207.00784},
  selected={false}
}

@inproceedings{xu2022mind,
  abbr={ECCV},
  title={Mind the Gap in Distilling StyleGANs},
  author={Xu, Guodong and Hou, Yuenan and Liu, Ziwei and Loy, Chen Change},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXXIII},
  pages={423--439},
  year={2022},
  organization={Springer},
  doi={https://doi.org/10.1007/978-3-031-19827-4_25},
  url={https://dl.acm.org/doi/abs/10.1007/978-3-031-19827-4_25},
  html={https://arxiv.org/abs/2208.08840},
  pdf={xu2022mind.pdf},
  selected={false}
}

@inproceedings{cong2022stcrowd,
  abbr={CVPR},
  title={Stcrowd: A multimodal dataset for pedestrian perception in crowded scenes},
  author={Cong, Peishan and Zhu, Xinge and Qiao, Feng and Ren, Yiming and Peng, Xidong and Hou, Yuenan and Xu, Lan and Yang, Ruigang and Manocha, Dinesh and Ma, Yuexin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19608--19617},
  year={2022},
  doi={https://doi.org/10.1109/CVPR52688.2022.01899},
  url={https://openaccess.thecvf.com/content/CVPR2022/html/Cong_STCrowd_A_Multimodal_Dataset_for_Pedestrian_Perception_in_Crowded_Scenes_CVPR_2022_paper.html},
  html={https://arxiv.org/abs/2204.01026},
  pdf={cong2022stcrowd.pdf},
  selected={false}
}

@inproceedings{ye2022b,
  abbr={CVPR},
  title={b-darts: Beta-decay regularization for differentiable architecture search},
  author={Ye, Peng and Li, Baopu and Li, Yikang and Chen, Tao and Fan, Jiayuan and Ouyang, Wanli},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10874--10883},
  year={2022},
  doi={https://doi.org/10.1109/CVPR52688.2022.01060},
  url={https://openaccess.thecvf.com/content/CVPR2022/html/Ye_b-DARTS_Beta-Decay_Regularization_for_Differentiable_Architecture_Search_CVPR_2022_paper.html},
  html={https://arxiv.org/abs/2203.01665},
  pdf={ye2022b.pdf},
  selected={false}
}